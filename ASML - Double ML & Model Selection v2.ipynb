{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c54e76ab-565b-4034-9fb6-ffcb93ffee01",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ASML Case Study - Bias Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf93e14c-22ea-46c2-be92-b1164029ffb3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SETTING UP THE ENVIRONMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c87042-c23e-4aaf-acdc-3b9ba39e5726",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4ea28ed-3044-44c6-9014-f5a62e6e3f60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statsmodels as sm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54c07681-6d27-403c-a0d5-d91308a84e7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Case study libraries\n",
    "from ASML_functions import get_residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6ab48c-e39d-4a33-91fc-da53d5a7c6f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e84f0ebd-317b-41fd-bda1-9abb457f8e28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nasml = pd.read_excel(\"ASML case data 2024.xlsx\")\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code for just the first sheet\n",
    "'''\n",
    "asml = pd.read_excel(\"ASML case data 2024.xlsx\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbc98ed9-21fd-4060-9185-b09f5c7fd32a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all sheets combined together\n",
    "asml_sheet_dict = pd.read_excel(\"ASML case data 2024.xlsx\", sheet_name=None)\n",
    "asml = pd.concat(asml_sheet_dict.values(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b68d6ef5-77d6-4d1e-bdbc-73d2f6f8d9bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7350, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asml.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6477726b-1fd7-4dab-ab45-0d8ff2bc8428",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wafer_id</th>\n",
       "      <th>field_center_x</th>\n",
       "      <th>field_center_y</th>\n",
       "      <th>intra_field_x</th>\n",
       "      <th>intra_field_y</th>\n",
       "      <th>wafer_coordinate_x_mm</th>\n",
       "      <th>wafer_coordinate_y_mm</th>\n",
       "      <th>Design_y_nm</th>\n",
       "      <th>Yieldproxy_y_perc</th>\n",
       "      <th>OVL_y_nm</th>\n",
       "      <th>L1_CD_y_nm</th>\n",
       "      <th>L2_CD_y_nm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-129.5348</td>\n",
       "      <td>-31.7107</td>\n",
       "      <td>-4.281</td>\n",
       "      <td>1.693</td>\n",
       "      <td>-0.133816</td>\n",
       "      <td>-0.030018</td>\n",
       "      <td>8</td>\n",
       "      <td>99.990000</td>\n",
       "      <td>-2.503573</td>\n",
       "      <td>20.732029</td>\n",
       "      <td>31.053869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-129.5348</td>\n",
       "      <td>-31.7107</td>\n",
       "      <td>-4.269</td>\n",
       "      <td>1.693</td>\n",
       "      <td>-0.133804</td>\n",
       "      <td>-0.030018</td>\n",
       "      <td>8</td>\n",
       "      <td>97.304645</td>\n",
       "      <td>-2.976532</td>\n",
       "      <td>22.140331</td>\n",
       "      <td>30.229045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-129.5348</td>\n",
       "      <td>-31.7107</td>\n",
       "      <td>-4.269</td>\n",
       "      <td>1.705</td>\n",
       "      <td>-0.133804</td>\n",
       "      <td>-0.030006</td>\n",
       "      <td>8</td>\n",
       "      <td>98.844177</td>\n",
       "      <td>-3.020233</td>\n",
       "      <td>21.859952</td>\n",
       "      <td>30.084430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-129.5348</td>\n",
       "      <td>-31.7107</td>\n",
       "      <td>-4.257</td>\n",
       "      <td>1.693</td>\n",
       "      <td>-0.133792</td>\n",
       "      <td>-0.030018</td>\n",
       "      <td>8</td>\n",
       "      <td>99.990000</td>\n",
       "      <td>-3.319554</td>\n",
       "      <td>22.780664</td>\n",
       "      <td>30.107721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-129.5348</td>\n",
       "      <td>-31.7107</td>\n",
       "      <td>-4.257</td>\n",
       "      <td>1.705</td>\n",
       "      <td>-0.133792</td>\n",
       "      <td>-0.030006</td>\n",
       "      <td>8</td>\n",
       "      <td>97.997447</td>\n",
       "      <td>-3.444417</td>\n",
       "      <td>22.489603</td>\n",
       "      <td>29.441237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wafer_id  field_center_x  field_center_y  intra_field_x  intra_field_y  \\\n",
       "0         1       -129.5348        -31.7107         -4.281          1.693   \n",
       "1         1       -129.5348        -31.7107         -4.269          1.693   \n",
       "2         1       -129.5348        -31.7107         -4.269          1.705   \n",
       "3         1       -129.5348        -31.7107         -4.257          1.693   \n",
       "4         1       -129.5348        -31.7107         -4.257          1.705   \n",
       "\n",
       "   wafer_coordinate_x_mm  wafer_coordinate_y_mm  Design_y_nm  \\\n",
       "0              -0.133816              -0.030018            8   \n",
       "1              -0.133804              -0.030018            8   \n",
       "2              -0.133804              -0.030006            8   \n",
       "3              -0.133792              -0.030018            8   \n",
       "4              -0.133792              -0.030006            8   \n",
       "\n",
       "   Yieldproxy_y_perc  OVL_y_nm  L1_CD_y_nm  L2_CD_y_nm  \n",
       "0          99.990000 -2.503573   20.732029   31.053869  \n",
       "1          97.304645 -2.976532   22.140331   30.229045  \n",
       "2          98.844177 -3.020233   21.859952   30.084430  \n",
       "3          99.990000 -3.319554   22.780664   30.107721  \n",
       "4          97.997447 -3.444417   22.489603   29.441237  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asml.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419aa36f-4599-4503-aa47-b8c7d0e8bb7f",
   "metadata": {},
   "source": [
    "### Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7817734-7724-4a1c-80ae-b68ffb702511",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wafer_id</th>\n",
       "      <th>field_center_x</th>\n",
       "      <th>field_center_y</th>\n",
       "      <th>intra_field_x</th>\n",
       "      <th>intra_field_y</th>\n",
       "      <th>coordinate_x</th>\n",
       "      <th>coordinate_y</th>\n",
       "      <th>Yield</th>\n",
       "      <th>OVL</th>\n",
       "      <th>L1_CD</th>\n",
       "      <th>L2_CD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-129.5348</td>\n",
       "      <td>-31.7107</td>\n",
       "      <td>-4.281</td>\n",
       "      <td>1.693</td>\n",
       "      <td>-0.133816</td>\n",
       "      <td>-0.030018</td>\n",
       "      <td>99.990000</td>\n",
       "      <td>-2.503573</td>\n",
       "      <td>20.732029</td>\n",
       "      <td>31.053869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-129.5348</td>\n",
       "      <td>-31.7107</td>\n",
       "      <td>-4.269</td>\n",
       "      <td>1.693</td>\n",
       "      <td>-0.133804</td>\n",
       "      <td>-0.030018</td>\n",
       "      <td>97.304645</td>\n",
       "      <td>-2.976532</td>\n",
       "      <td>22.140331</td>\n",
       "      <td>30.229045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-129.5348</td>\n",
       "      <td>-31.7107</td>\n",
       "      <td>-4.269</td>\n",
       "      <td>1.705</td>\n",
       "      <td>-0.133804</td>\n",
       "      <td>-0.030006</td>\n",
       "      <td>98.844177</td>\n",
       "      <td>-3.020233</td>\n",
       "      <td>21.859952</td>\n",
       "      <td>30.084430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-129.5348</td>\n",
       "      <td>-31.7107</td>\n",
       "      <td>-4.257</td>\n",
       "      <td>1.693</td>\n",
       "      <td>-0.133792</td>\n",
       "      <td>-0.030018</td>\n",
       "      <td>99.990000</td>\n",
       "      <td>-3.319554</td>\n",
       "      <td>22.780664</td>\n",
       "      <td>30.107721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-129.5348</td>\n",
       "      <td>-31.7107</td>\n",
       "      <td>-4.257</td>\n",
       "      <td>1.705</td>\n",
       "      <td>-0.133792</td>\n",
       "      <td>-0.030006</td>\n",
       "      <td>97.997447</td>\n",
       "      <td>-3.444417</td>\n",
       "      <td>22.489603</td>\n",
       "      <td>29.441237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wafer_id  field_center_x  field_center_y  intra_field_x  intra_field_y  \\\n",
       "0         1       -129.5348        -31.7107         -4.281          1.693   \n",
       "1         1       -129.5348        -31.7107         -4.269          1.693   \n",
       "2         1       -129.5348        -31.7107         -4.269          1.705   \n",
       "3         1       -129.5348        -31.7107         -4.257          1.693   \n",
       "4         1       -129.5348        -31.7107         -4.257          1.705   \n",
       "\n",
       "   coordinate_x  coordinate_y      Yield       OVL      L1_CD      L2_CD  \n",
       "0     -0.133816     -0.030018  99.990000 -2.503573  20.732029  31.053869  \n",
       "1     -0.133804     -0.030018  97.304645 -2.976532  22.140331  30.229045  \n",
       "2     -0.133804     -0.030006  98.844177 -3.020233  21.859952  30.084430  \n",
       "3     -0.133792     -0.030018  99.990000 -3.319554  22.780664  30.107721  \n",
       "4     -0.133792     -0.030006  97.997447 -3.444417  22.489603  29.441237  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asml.drop(\"Design_y_nm\", axis='columns', inplace=True)\n",
    "asml.rename(columns={'wafer_coordinate_x_mm': 'coordinate_x', 'wafer_coordinate_y_mm': 'coordinate_y',\n",
    "                   'Yieldproxy_y_perc': 'Yield', 'OVL_y_nm': 'OVL', 'L1_CD_y_nm': 'L1_CD', 'L2_CD_y_nm': 'L2_CD',}, inplace=True)\n",
    "asml.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be6e251d-713e-43d4-b335-c90830da41d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wafer_id</th>\n",
       "      <th>field_center_x</th>\n",
       "      <th>field_center_y</th>\n",
       "      <th>intra_field_x</th>\n",
       "      <th>intra_field_y</th>\n",
       "      <th>coordinate_x</th>\n",
       "      <th>coordinate_y</th>\n",
       "      <th>Yield</th>\n",
       "      <th>OVL</th>\n",
       "      <th>L1_CD</th>\n",
       "      <th>L2_CD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-129.5348</td>\n",
       "      <td>-31.7107</td>\n",
       "      <td>-4.281</td>\n",
       "      <td>1.693</td>\n",
       "      <td>-0.133816</td>\n",
       "      <td>-0.030018</td>\n",
       "      <td>99.990000</td>\n",
       "      <td>2.503573</td>\n",
       "      <td>20.732029</td>\n",
       "      <td>31.053869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-129.5348</td>\n",
       "      <td>-31.7107</td>\n",
       "      <td>-4.269</td>\n",
       "      <td>1.693</td>\n",
       "      <td>-0.133804</td>\n",
       "      <td>-0.030018</td>\n",
       "      <td>97.304645</td>\n",
       "      <td>2.976532</td>\n",
       "      <td>22.140331</td>\n",
       "      <td>30.229045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-129.5348</td>\n",
       "      <td>-31.7107</td>\n",
       "      <td>-4.269</td>\n",
       "      <td>1.705</td>\n",
       "      <td>-0.133804</td>\n",
       "      <td>-0.030006</td>\n",
       "      <td>98.844177</td>\n",
       "      <td>3.020233</td>\n",
       "      <td>21.859952</td>\n",
       "      <td>30.084430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-129.5348</td>\n",
       "      <td>-31.7107</td>\n",
       "      <td>-4.257</td>\n",
       "      <td>1.693</td>\n",
       "      <td>-0.133792</td>\n",
       "      <td>-0.030018</td>\n",
       "      <td>99.990000</td>\n",
       "      <td>3.319554</td>\n",
       "      <td>22.780664</td>\n",
       "      <td>30.107721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-129.5348</td>\n",
       "      <td>-31.7107</td>\n",
       "      <td>-4.257</td>\n",
       "      <td>1.705</td>\n",
       "      <td>-0.133792</td>\n",
       "      <td>-0.030006</td>\n",
       "      <td>97.997447</td>\n",
       "      <td>3.444417</td>\n",
       "      <td>22.489603</td>\n",
       "      <td>29.441237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   wafer_id  field_center_x  field_center_y  intra_field_x  intra_field_y  \\\n",
       "0         1       -129.5348        -31.7107         -4.281          1.693   \n",
       "1         1       -129.5348        -31.7107         -4.269          1.693   \n",
       "2         1       -129.5348        -31.7107         -4.269          1.705   \n",
       "3         1       -129.5348        -31.7107         -4.257          1.693   \n",
       "4         1       -129.5348        -31.7107         -4.257          1.705   \n",
       "\n",
       "   coordinate_x  coordinate_y      Yield       OVL      L1_CD      L2_CD  \n",
       "0     -0.133816     -0.030018  99.990000  2.503573  20.732029  31.053869  \n",
       "1     -0.133804     -0.030018  97.304645  2.976532  22.140331  30.229045  \n",
       "2     -0.133804     -0.030006  98.844177  3.020233  21.859952  30.084430  \n",
       "3     -0.133792     -0.030018  99.990000  3.319554  22.780664  30.107721  \n",
       "4     -0.133792     -0.030006  97.997447  3.444417  22.489603  29.441237  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting overlay to absolute overlay\n",
    "asml['OVL'] = abs(asml['OVL'])\n",
    "asml.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f6cf02-45b6-4a3a-8991-4ad666a6ce96",
   "metadata": {
    "tags": []
   },
   "source": [
    "## BIAS REDUCTION WITH DOUBLE MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda69559-7596-41b9-887b-6bd691d7bbe4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Positional dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55719a5e-3a9b-456b-8cc6-3267ca419669",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field_center_x</th>\n",
       "      <th>field_center_y</th>\n",
       "      <th>intra_field_x</th>\n",
       "      <th>intra_field_y</th>\n",
       "      <th>coordinate_x</th>\n",
       "      <th>coordinate_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-129.5348</td>\n",
       "      <td>-31.7107</td>\n",
       "      <td>-4.281</td>\n",
       "      <td>1.693</td>\n",
       "      <td>-0.133816</td>\n",
       "      <td>-0.030018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-129.5348</td>\n",
       "      <td>-31.7107</td>\n",
       "      <td>-4.269</td>\n",
       "      <td>1.693</td>\n",
       "      <td>-0.133804</td>\n",
       "      <td>-0.030018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-129.5348</td>\n",
       "      <td>-31.7107</td>\n",
       "      <td>-4.269</td>\n",
       "      <td>1.705</td>\n",
       "      <td>-0.133804</td>\n",
       "      <td>-0.030006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-129.5348</td>\n",
       "      <td>-31.7107</td>\n",
       "      <td>-4.257</td>\n",
       "      <td>1.693</td>\n",
       "      <td>-0.133792</td>\n",
       "      <td>-0.030018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-129.5348</td>\n",
       "      <td>-31.7107</td>\n",
       "      <td>-4.257</td>\n",
       "      <td>1.705</td>\n",
       "      <td>-0.133792</td>\n",
       "      <td>-0.030006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   field_center_x  field_center_y  intra_field_x  intra_field_y  coordinate_x  \\\n",
       "0       -129.5348        -31.7107         -4.281          1.693     -0.133816   \n",
       "1       -129.5348        -31.7107         -4.269          1.693     -0.133804   \n",
       "2       -129.5348        -31.7107         -4.269          1.705     -0.133804   \n",
       "3       -129.5348        -31.7107         -4.257          1.693     -0.133792   \n",
       "4       -129.5348        -31.7107         -4.257          1.705     -0.133792   \n",
       "\n",
       "   coordinate_y  \n",
       "0     -0.030018  \n",
       "1     -0.030018  \n",
       "2     -0.030006  \n",
       "3     -0.030018  \n",
       "4     -0.030006  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asml_geo_data = asml[['field_center_x', 'field_center_y', 'intra_field_x', 'intra_field_y', 'coordinate_x', 'coordinate_y']]\n",
    "asml_geo_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e6fbe9-ae53-432b-96ef-030c99aa210c",
   "metadata": {},
   "source": [
    "###  Finding the best ML model for OVL, CD1 and CD2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a58463f-9d24-4b5c-94ab-78aefddf070c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARDRegression\n",
      "AdaBoostRegressor\n",
      "BaggingRegressor\n",
      "BayesianRidge\n",
      "CCA\n",
      "DecisionTreeRegressor\n",
      "DummyRegressor\n",
      "ElasticNet\n",
      "ElasticNetCV\n",
      "ExtraTreeRegressor\n",
      "ExtraTreesRegressor\n",
      "GammaRegressor\n",
      "GaussianProcessRegressor\n",
      "GradientBoostingRegressor\n",
      "HistGradientBoostingRegressor\n",
      "HuberRegressor\n",
      "IsotonicRegression\n",
      "KNeighborsRegressor\n",
      "KernelRidge\n",
      "Lars\n",
      "LarsCV\n",
      "Lasso\n",
      "LassoCV\n",
      "LassoLars\n",
      "LassoLarsCV\n",
      "LassoLarsIC\n",
      "LinearRegression\n",
      "LinearSVR\n",
      "MLPRegressor\n",
      "MultiOutputRegressor\n",
      "MultiTaskElasticNet\n",
      "MultiTaskElasticNetCV\n",
      "MultiTaskLasso\n",
      "MultiTaskLassoCV\n",
      "NuSVR\n",
      "OrthogonalMatchingPursuit\n",
      "OrthogonalMatchingPursuitCV\n",
      "PLSCanonical\n",
      "PLSRegression\n",
      "PassiveAggressiveRegressor\n",
      "PoissonRegressor\n",
      "QuantileRegressor\n",
      "RANSACRegressor\n",
      "RadiusNeighborsRegressor\n",
      "RandomForestRegressor\n",
      "RegressorChain\n",
      "Ridge\n",
      "RidgeCV\n",
      "SGDRegressor\n",
      "SVR\n",
      "StackingRegressor\n",
      "TheilSenRegressor\n",
      "TransformedTargetRegressor\n",
      "TweedieRegressor\n",
      "VotingRegressor\n"
     ]
    }
   ],
   "source": [
    "# trying to fit all the predictive ML models in sklearn and choosing the best one of them\n",
    "from sklearn.utils import all_estimators\n",
    "\n",
    "# Get all estimators of type 'regressor'\n",
    "# type_filter{“classifier”, “regressor”, “cluster”, “transformer”}\n",
    "estimators = all_estimators(type_filter='regressor')\n",
    "\n",
    "# Loop through the list of tuples to print just the name\n",
    "for name, model in estimators:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b1a4c77-639d-4501-a4e8-b4eee08b4802",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# escluding estimators that cause issues in the double machine learning custom function\n",
    "exclusions = {'QuantileRegressor'}\n",
    "estimators = [(name, cls) for name, cls in estimators if name not in exclusions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d306cdc8-7cbc-4279-a9d0-2343e54c3e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL ----------------------------- CV R^2\n",
      "\u001b[38;5;19mARDRegression                       73.08%\u001b[0m\n",
      "\u001b[38;5;19mAdaBoostRegressor                   72.80%\u001b[0m\n",
      "\u001b[38;5;19mBaggingRegressor                    66.26%\u001b[0m\n",
      "\u001b[38;5;19mBayesianRidge                       73.09%\u001b[0m\n",
      "\u001b[0;31mCCA                                 \u001b[1mModel fit error:\u001b[0m\u001b[0;31m `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\u001b[0m\n",
      "\u001b[38;5;19mDecisionTreeRegressor               66.05%\u001b[0m\n",
      "\u001b[38;5;19mDummyRegressor                      -0.02%\u001b[0m\n",
      "\u001b[38;5;19mElasticNet                          -0.05%\u001b[0m\n",
      "\u001b[38;5;19mElasticNetCV                        25.13%\u001b[0m\n",
      "\u001b[38;5;19mExtraTreeRegressor                  66.04%\u001b[0m\n",
      "\u001b[38;5;19mExtraTreesRegressor                 66.05%\u001b[0m\n",
      "\u001b[38;5;19mGammaRegressor                      0.00%\u001b[0m\n",
      "\u001b[38;5;19mGaussianProcessRegressor            70.89%\u001b[0m\n",
      "\u001b[38;5;19mGradientBoostingRegressor           74.91%\u001b[0m\n",
      "\u001b[38;5;19mHistGradientBoostingRegressor       74.96%\u001b[0m\n",
      "\u001b[38;5;19mHuberRegressor                      72.87%\u001b[0m\n",
      "\u001b[0mWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "\n",
      "\u001b[0;31mIsotonicRegression                  \u001b[1mModel fit error:\u001b[0m\u001b[0;31m Isotonic regression input X should be a 1d array or 2d array with 1 feature\u001b[0m\n",
      "\u001b[38;5;19mKNeighborsRegressor                 65.52%\u001b[0m\n",
      "\u001b[38;5;19mKernelRidge                         11.62%\u001b[0m\n",
      "\u001b[38;5;19mLars                                73.09%\u001b[0m\n",
      "\u001b[38;5;19mLarsCV                              73.09%\u001b[0m\n",
      "\u001b[0mWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=1.371e-07, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "\u001b[0mWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=3.178e-06, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "\u001b[0mWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.965e-06, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "\u001b[0mWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=4.565e-06, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "\u001b[38;5;19mLasso                               -0.04%\u001b[0m\n",
      "\u001b[38;5;19mLassoCV                             71.35%\u001b[0m\n",
      "\u001b[38;5;19mLassoLars                           -0.04%\u001b[0m\n",
      "\u001b[38;5;19mLassoLarsCV                         73.09%\u001b[0m\n",
      "\u001b[38;5;19mLassoLarsIC                         73.09%\u001b[0m\n",
      "\u001b[38;5;19mLinearRegression                    73.09%\u001b[0m\n",
      "\u001b[38;5;19mLinearSVR                           -125.18%\u001b[0m\n",
      "\u001b[0mWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "\n",
      "\u001b[0mWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "\n",
      "\u001b[38;5;19mMLPRegressor                        -9.56%\u001b[0m\n",
      "\u001b[0;31mMultiOutputRegressor                \u001b[1mFailed instantiating, model is likely a meta estimator:\u001b[0m\u001b[0;31m MultiOutputRegressor.__init__() missing 1 required positional argument: 'estimator'\u001b[0m\n",
      "\u001b[0;31mMultiTaskElasticNet                 \u001b[1mModel fit error:\u001b[0m\u001b[0;31m For mono-task outputs, use ElasticNet\u001b[0m\n",
      "\u001b[0;31mMultiTaskElasticNetCV               \u001b[1mModel fit error:\u001b[0m\u001b[0;31m For mono-task outputs, use ElasticNetCVCV\u001b[0m\n",
      "\u001b[0;31mMultiTaskLasso                      \u001b[1mModel fit error:\u001b[0m\u001b[0;31m For mono-task outputs, use ElasticNet\u001b[0m\n",
      "\u001b[0;31mMultiTaskLassoCV                    \u001b[1mModel fit error:\u001b[0m\u001b[0;31m For mono-task outputs, use LassoCVCV\u001b[0m\n",
      "\u001b[38;5;19mNuSVR                               0.11%\u001b[0m\n",
      "\u001b[38;5;19mOrthogonalMatchingPursuit           -0.06%\u001b[0m\n",
      "\u001b[38;5;19mOrthogonalMatchingPursuitCV         73.09%\u001b[0m\n",
      "\u001b[0mWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "\u001b[0;31mPLSCanonical                        \u001b[1mModel fit error:\u001b[0m\u001b[0;31m `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\u001b[0m\n",
      "\u001b[38;5;19mPLSRegression                       73.09%\u001b[0m\n",
      "\u001b[38;5;19mPassiveAggressiveRegressor          -615.39%\u001b[0m\n",
      "\u001b[38;5;19mPoissonRegressor                    0.84%\u001b[0m\n",
      "\u001b[38;5;19mRANSACRegressor                     70.60%\u001b[0m\n",
      "\u001b[38;5;19mRadiusNeighborsRegressor            0.40%\u001b[0m\n",
      "\u001b[38;5;19mRandomForestRegressor               67.26%\u001b[0m\n",
      "\u001b[0;31mRegressorChain                      \u001b[1mFailed instantiating, model is likely a meta estimator:\u001b[0m\u001b[0;31m _BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\u001b[0m\n",
      "\u001b[38;5;19mRidge                               61.63%\u001b[0m\n",
      "\u001b[38;5;19mRidgeCV                             72.71%\u001b[0m\n",
      "\u001b[38;5;19mSGDRegressor                        -101325915331635988066729984.00%\u001b[0m\n",
      "\u001b[38;5;19mSVR                                 0.16%\u001b[0m\n",
      "\u001b[0;31mStackingRegressor                   \u001b[1mFailed instantiating, model is likely a meta estimator:\u001b[0m\u001b[0;31m StackingRegressor.__init__() missing 1 required positional argument: 'estimators'\u001b[0m\n",
      "\u001b[38;5;19mTheilSenRegressor                   72.99%\u001b[0m\n",
      "\u001b[38;5;19mTransformedTargetRegressor          73.09%\u001b[0m\n",
      "\u001b[38;5;19mTweedieRegressor                    -0.00%\u001b[0m\n",
      "\u001b[0;31mVotingRegressor                     \u001b[1mFailed instantiating, model is likely a meta estimator:\u001b[0m\u001b[0;31m VotingRegressor.__init__() missing 1 required positional argument: 'estimators'\u001b[0m\n",
      "\u001b[0m-----------------------------------------------------\n",
      "RESULTS TABLE                       CV R^2\n",
      "\u001b[38;5;19mHistGradientBoostingRegressor       74.96%\n",
      "\u001b[38;5;19mGradientBoostingRegressor           74.91%\n",
      "\u001b[38;5;19mPLSRegression                       73.09%\n",
      "\u001b[38;5;19mBayesianRidge                       73.09%\n",
      "\u001b[38;5;19mLinearRegression                    73.09%\n",
      "\u001b[38;5;19mTransformedTargetRegressor          73.09%\n",
      "\u001b[38;5;19mOrthogonalMatchingPursuitCV         73.09%\n",
      "\u001b[38;5;19mLars                                73.09%\n",
      "\u001b[38;5;19mLassoLarsCV                         73.09%\n",
      "\u001b[38;5;19mLassoLarsIC                         73.09%\n",
      "\u001b[38;5;19mLarsCV                              73.09%\n",
      "\u001b[38;5;19mARDRegression                       73.08%\n",
      "\u001b[38;5;19mTheilSenRegressor                   72.99%\n",
      "\u001b[38;5;19mHuberRegressor                      72.87%\n",
      "\u001b[38;5;19mAdaBoostRegressor                   72.80%\n",
      "\u001b[38;5;19mRidgeCV                             72.71%\n",
      "\u001b[38;5;19mLassoCV                             71.35%\n",
      "\u001b[38;5;19mGaussianProcessRegressor            70.89%\n",
      "\u001b[38;5;19mRANSACRegressor                     70.60%\n",
      "\u001b[38;5;19mRandomForestRegressor               67.26%\n",
      "\u001b[38;5;19mBaggingRegressor                    66.26%\n",
      "\u001b[38;5;19mExtraTreesRegressor                 66.05%\n",
      "\u001b[38;5;19mDecisionTreeRegressor               66.05%\n",
      "\u001b[38;5;19mExtraTreeRegressor                  66.04%\n",
      "\u001b[38;5;19mKNeighborsRegressor                 65.52%\n",
      "\u001b[38;5;19mRidge                               61.63%\n",
      "\u001b[38;5;19mElasticNetCV                        25.13%\n",
      "\u001b[38;5;19mKernelRidge                         11.62%\n",
      "\u001b[38;5;19mPoissonRegressor                    0.84%\n",
      "\u001b[38;5;19mRadiusNeighborsRegressor            0.40%\n",
      "\u001b[38;5;19mSVR                                 0.16%\n",
      "\u001b[38;5;19mNuSVR                               0.11%\n",
      "\u001b[38;5;19mGammaRegressor                      0.00%\n",
      "\u001b[38;5;19mTweedieRegressor                    -0.00%\n",
      "\u001b[38;5;19mDummyRegressor                      -0.02%\n",
      "\u001b[38;5;19mLasso                               -0.04%\n",
      "\u001b[38;5;19mLassoLars                           -0.04%\n",
      "\u001b[38;5;19mElasticNet                          -0.05%\n",
      "\u001b[38;5;19mOrthogonalMatchingPursuit           -0.06%\n",
      "\u001b[38;5;19mMLPRegressor                        -9.56%\n",
      "\u001b[38;5;19mLinearSVR                           -125.18%\n",
      "\u001b[38;5;19mPassiveAggressiveRegressor          -615.39%\n",
      "\u001b[38;5;19mSGDRegressor                        -101325915331635988066729984.00%\n",
      "\u001b[0;31mMultiOutputRegressor                FAIL - instantiating\n",
      "\u001b[0;31mRegressorChain                      FAIL - instantiating\n",
      "\u001b[0;31mStackingRegressor                   FAIL - instantiating\n",
      "\u001b[0;31mVotingRegressor                     FAIL - instantiating\n",
      "\u001b[0;31mCCA                                 FAIL - Fitting\n",
      "\u001b[0;31mIsotonicRegression                  FAIL - Fitting\n",
      "\u001b[0;31mMultiTaskElasticNet                 FAIL - Fitting\n",
      "\u001b[0;31mMultiTaskElasticNetCV               FAIL - Fitting\n",
      "\u001b[0;31mMultiTaskLasso                      FAIL - Fitting\n",
      "\u001b[0;31mMultiTaskLassoCV                    FAIL - Fitting\n",
      "\u001b[0;31mPLSCanonical                        FAIL - Fitting\n",
      "\u001b[0m-----------------------------------------------------\n",
      "BEST MODEL:                         \u001b[0;32m\u001b[1mHistGradientBoostingRegressor\u001b[0m\n",
      "CV R^2:                             \u001b[0;32m74.9575%\u001b[0m\n",
      "R^2:                                \u001b[0;32m78.2421%\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Cross validating all models and choosing the one that best predicts L1_CD using positional data in cross validation. \n",
    "# Then, fitting the model with all data and getting the residuals.\n",
    "# The same will be done with OVL, L1 CD and L2 CD. \n",
    "# We will then have a residuals dataset which had the positional bias \n",
    "# removed with the best ML algorithm for the respective variable.\n",
    "\n",
    "best_model_name_L1_CD, best_model_L1_CD, y_pred_L1_CD, residuals_L1_CD, results_table_L1_CD = get_residuals(asml_geo_data, asml['L1_CD'], models = estimators, random_seed = 123, timeout= 120, display_warnings = True, print_results_table = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71786b7d-5a45-4989-a0b6-601cf91f9dc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL ----------------------------- CV R^2\n",
      "\u001b[38;5;19mARDRegression                       62.01%\u001b[0m\n",
      "\u001b[38;5;19mAdaBoostRegressor                   63.38%\u001b[0m\n",
      "\u001b[38;5;19mBaggingRegressor                    50.93%\u001b[0m\n",
      "\u001b[38;5;19mBayesianRidge                       62.01%\u001b[0m\n",
      "\u001b[0;31mCCA                                 \u001b[1mModel fit error:\u001b[0m\u001b[0;31m `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\u001b[0m\n",
      "\u001b[38;5;19mDecisionTreeRegressor               50.45%\u001b[0m\n",
      "\u001b[38;5;19mDummyRegressor                      -0.01%\u001b[0m\n",
      "\u001b[38;5;19mElasticNet                          -0.03%\u001b[0m\n",
      "\u001b[38;5;19mElasticNetCV                        22.60%\u001b[0m\n",
      "\u001b[38;5;19mExtraTreeRegressor                  50.45%\u001b[0m\n",
      "\u001b[38;5;19mExtraTreesRegressor                 50.45%\u001b[0m\n",
      "\u001b[38;5;19mGammaRegressor                      -0.03%\u001b[0m\n",
      "\u001b[38;5;19mGaussianProcessRegressor            57.81%\u001b[0m\n",
      "\u001b[38;5;19mGradientBoostingRegressor           64.24%\u001b[0m\n",
      "\u001b[38;5;19mHistGradientBoostingRegressor       63.45%\u001b[0m\n",
      "\u001b[38;5;19mHuberRegressor                      61.84%\u001b[0m\n",
      "\u001b[0mWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "\n",
      "\u001b[0;31mIsotonicRegression                  \u001b[1mModel fit error:\u001b[0m\u001b[0;31m Isotonic regression input X should be a 1d array or 2d array with 1 feature\u001b[0m\n",
      "\u001b[38;5;19mKNeighborsRegressor                 52.77%\u001b[0m\n",
      "\u001b[38;5;19mKernelRidge                         23.15%\u001b[0m\n",
      "\u001b[38;5;19mLars                                62.01%\u001b[0m\n",
      "\u001b[38;5;19mLarsCV                              62.01%\u001b[0m\n",
      "\u001b[38;5;19mLasso                               -0.02%\u001b[0m\n",
      "\u001b[38;5;19mLassoCV                             61.49%\u001b[0m\n",
      "\u001b[38;5;19mLassoLars                           -0.02%\u001b[0m\n",
      "\u001b[38;5;19mLassoLarsCV                         62.01%\u001b[0m\n",
      "\u001b[38;5;19mLassoLarsIC                         62.01%\u001b[0m\n",
      "\u001b[38;5;19mLinearRegression                    62.01%\u001b[0m\n",
      "\u001b[38;5;19mLinearSVR                           -156.96%\u001b[0m\n",
      "\u001b[0mWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "\n",
      "\u001b[0mWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "\n",
      "\u001b[38;5;19mMLPRegressor                        7.16%\u001b[0m\n",
      "\u001b[0;31mMultiOutputRegressor                \u001b[1mFailed instantiating, model is likely a meta estimator:\u001b[0m\u001b[0;31m MultiOutputRegressor.__init__() missing 1 required positional argument: 'estimator'\u001b[0m\n",
      "\u001b[0;31mMultiTaskElasticNet                 \u001b[1mModel fit error:\u001b[0m\u001b[0;31m For mono-task outputs, use ElasticNet\u001b[0m\n",
      "\u001b[0;31mMultiTaskElasticNetCV               \u001b[1mModel fit error:\u001b[0m\u001b[0;31m For mono-task outputs, use ElasticNetCVCV\u001b[0m\n",
      "\u001b[0;31mMultiTaskLasso                      \u001b[1mModel fit error:\u001b[0m\u001b[0;31m For mono-task outputs, use ElasticNet\u001b[0m\n",
      "\u001b[0;31mMultiTaskLassoCV                    \u001b[1mModel fit error:\u001b[0m\u001b[0;31m For mono-task outputs, use LassoCVCV\u001b[0m\n",
      "\u001b[38;5;19mNuSVR                               -0.06%\u001b[0m\n",
      "\u001b[38;5;19mOrthogonalMatchingPursuit           -0.03%\u001b[0m\n",
      "\u001b[38;5;19mOrthogonalMatchingPursuitCV         62.01%\u001b[0m\n",
      "\u001b[0mWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "\u001b[0;31mPLSCanonical                        \u001b[1mModel fit error:\u001b[0m\u001b[0;31m `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\u001b[0m\n",
      "\u001b[38;5;19mPLSRegression                       62.02%\u001b[0m\n",
      "\u001b[38;5;19mPassiveAggressiveRegressor          -198.22%\u001b[0m\n",
      "\u001b[38;5;19mPoissonRegressor                    1.01%\u001b[0m\n",
      "\u001b[38;5;19mRANSACRegressor                     58.76%\u001b[0m\n",
      "\u001b[38;5;19mRadiusNeighborsRegressor            0.53%\u001b[0m\n",
      "\u001b[38;5;19mRandomForestRegressor               52.15%\u001b[0m\n",
      "\u001b[0;31mRegressorChain                      \u001b[1mFailed instantiating, model is likely a meta estimator:\u001b[0m\u001b[0;31m _BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\u001b[0m\n",
      "\u001b[38;5;19mRidge                               53.59%\u001b[0m\n",
      "\u001b[38;5;19mRidgeCV                             61.83%\u001b[0m\n",
      "\u001b[38;5;19mSGDRegressor                        -173980787020473140015792128.00%\u001b[0m\n",
      "\u001b[38;5;19mSVR                                 -0.68%\u001b[0m\n",
      "\u001b[0;31mStackingRegressor                   \u001b[1mFailed instantiating, model is likely a meta estimator:\u001b[0m\u001b[0;31m StackingRegressor.__init__() missing 1 required positional argument: 'estimators'\u001b[0m\n",
      "\u001b[38;5;19mTheilSenRegressor                   61.95%\u001b[0m\n",
      "\u001b[38;5;19mTransformedTargetRegressor          62.01%\u001b[0m\n",
      "\u001b[38;5;19mTweedieRegressor                    -0.01%\u001b[0m\n",
      "\u001b[0;31mVotingRegressor                     \u001b[1mFailed instantiating, model is likely a meta estimator:\u001b[0m\u001b[0;31m VotingRegressor.__init__() missing 1 required positional argument: 'estimators'\u001b[0m\n",
      "\u001b[0m-----------------------------------------------------\n",
      "RESULTS TABLE                       CV R^2\n",
      "\u001b[38;5;19mGradientBoostingRegressor           64.24%\n",
      "\u001b[38;5;19mHistGradientBoostingRegressor       63.45%\n",
      "\u001b[38;5;19mAdaBoostRegressor                   63.38%\n",
      "\u001b[38;5;19mPLSRegression                       62.02%\n",
      "\u001b[38;5;19mARDRegression                       62.01%\n",
      "\u001b[38;5;19mLinearRegression                    62.01%\n",
      "\u001b[38;5;19mTransformedTargetRegressor          62.01%\n",
      "\u001b[38;5;19mOrthogonalMatchingPursuitCV         62.01%\n",
      "\u001b[38;5;19mLars                                62.01%\n",
      "\u001b[38;5;19mLarsCV                              62.01%\n",
      "\u001b[38;5;19mLassoLarsCV                         62.01%\n",
      "\u001b[38;5;19mLassoLarsIC                         62.01%\n",
      "\u001b[38;5;19mBayesianRidge                       62.01%\n",
      "\u001b[38;5;19mTheilSenRegressor                   61.95%\n",
      "\u001b[38;5;19mHuberRegressor                      61.84%\n",
      "\u001b[38;5;19mRidgeCV                             61.83%\n",
      "\u001b[38;5;19mLassoCV                             61.49%\n",
      "\u001b[38;5;19mRANSACRegressor                     58.76%\n",
      "\u001b[38;5;19mGaussianProcessRegressor            57.81%\n",
      "\u001b[38;5;19mRidge                               53.59%\n",
      "\u001b[38;5;19mKNeighborsRegressor                 52.77%\n",
      "\u001b[38;5;19mRandomForestRegressor               52.15%\n",
      "\u001b[38;5;19mBaggingRegressor                    50.93%\n",
      "\u001b[38;5;19mExtraTreesRegressor                 50.45%\n",
      "\u001b[38;5;19mDecisionTreeRegressor               50.45%\n",
      "\u001b[38;5;19mExtraTreeRegressor                  50.45%\n",
      "\u001b[38;5;19mKernelRidge                         23.15%\n",
      "\u001b[38;5;19mElasticNetCV                        22.60%\n",
      "\u001b[38;5;19mMLPRegressor                        7.16%\n",
      "\u001b[38;5;19mPoissonRegressor                    1.01%\n",
      "\u001b[38;5;19mRadiusNeighborsRegressor            0.53%\n",
      "\u001b[38;5;19mTweedieRegressor                    -0.01%\n",
      "\u001b[38;5;19mDummyRegressor                      -0.01%\n",
      "\u001b[38;5;19mLasso                               -0.02%\n",
      "\u001b[38;5;19mLassoLars                           -0.02%\n",
      "\u001b[38;5;19mElasticNet                          -0.03%\n",
      "\u001b[38;5;19mGammaRegressor                      -0.03%\n",
      "\u001b[38;5;19mOrthogonalMatchingPursuit           -0.03%\n",
      "\u001b[38;5;19mNuSVR                               -0.06%\n",
      "\u001b[38;5;19mSVR                                 -0.68%\n",
      "\u001b[38;5;19mLinearSVR                           -156.96%\n",
      "\u001b[38;5;19mPassiveAggressiveRegressor          -198.22%\n",
      "\u001b[38;5;19mSGDRegressor                        -173980787020473140015792128.00%\n",
      "\u001b[0;31mMultiOutputRegressor                FAIL - instantiating\n",
      "\u001b[0;31mRegressorChain                      FAIL - instantiating\n",
      "\u001b[0;31mStackingRegressor                   FAIL - instantiating\n",
      "\u001b[0;31mVotingRegressor                     FAIL - instantiating\n",
      "\u001b[0;31mCCA                                 FAIL - Fitting\n",
      "\u001b[0;31mIsotonicRegression                  FAIL - Fitting\n",
      "\u001b[0;31mMultiTaskElasticNet                 FAIL - Fitting\n",
      "\u001b[0;31mMultiTaskElasticNetCV               FAIL - Fitting\n",
      "\u001b[0;31mMultiTaskLasso                      FAIL - Fitting\n",
      "\u001b[0;31mMultiTaskLassoCV                    FAIL - Fitting\n",
      "\u001b[0;31mPLSCanonical                        FAIL - Fitting\n",
      "\u001b[0m-----------------------------------------------------\n",
      "BEST MODEL:                         \u001b[0;32m\u001b[1mGradientBoostingRegressor\u001b[0m\n",
      "CV R^2:                             \u001b[0;32m64.2392%\u001b[0m\n",
      "R^2:                                \u001b[0;32m65.4752%\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_model_name_L2_CD, best_model_L2_CD, y_pred_L2_CD, residuals_L2_CD, results_table_L2_CD = get_residuals(asml_geo_data, asml['L2_CD'], models = estimators, random_seed = 123, timeout= 120, display_warnings = True, print_results_table = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5efcf700-2098-48e5-b751-5bbe83dc6613",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL ----------------------------- CV R^2\n",
      "\u001b[38;5;19mARDRegression                       3.16%\u001b[0m\n",
      "\u001b[38;5;19mAdaBoostRegressor                   0.56%\u001b[0m\n",
      "\u001b[38;5;19mBaggingRegressor                    -23.05%\u001b[0m\n",
      "\u001b[38;5;19mBayesianRidge                       3.20%\u001b[0m\n",
      "\u001b[0;31mCCA                                 \u001b[1mModel fit error:\u001b[0m\u001b[0;31m `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\u001b[0m\n",
      "\u001b[38;5;19mDecisionTreeRegressor               -25.19%\u001b[0m\n",
      "\u001b[38;5;19mDummyRegressor                      -0.00%\u001b[0m\n",
      "\u001b[38;5;19mElasticNet                          0.14%\u001b[0m\n",
      "\u001b[38;5;19mElasticNetCV                        -0.00%\u001b[0m\n",
      "\u001b[38;5;19mExtraTreeRegressor                  -25.28%\u001b[0m\n",
      "\u001b[38;5;19mExtraTreesRegressor                 -25.20%\u001b[0m\n",
      "\u001b[38;5;19mGammaRegressor                      0.13%\u001b[0m\n",
      "\u001b[38;5;19mGaussianProcessRegressor            -3.91%\u001b[0m\n",
      "\u001b[38;5;19mGradientBoostingRegressor           7.49%\u001b[0m\n",
      "\u001b[38;5;19mHistGradientBoostingRegressor       11.00%\u001b[0m\n",
      "\u001b[38;5;19mHuberRegressor                      -1.81%\u001b[0m\n",
      "\u001b[0;31mIsotonicRegression                  \u001b[1mModel fit error:\u001b[0m\u001b[0;31m Isotonic regression input X should be a 1d array or 2d array with 1 feature\u001b[0m\n",
      "\u001b[38;5;19mKNeighborsRegressor                 -6.87%\u001b[0m\n",
      "\u001b[38;5;19mKernelRidge                         0.72%\u001b[0m\n",
      "\u001b[38;5;19mLars                                3.20%\u001b[0m\n",
      "\u001b[38;5;19mLarsCV                              3.19%\u001b[0m\n",
      "\u001b[38;5;19mLasso                               0.13%\u001b[0m\n",
      "\u001b[38;5;19mLassoCV                             1.34%\u001b[0m\n",
      "\u001b[38;5;19mLassoLars                           0.13%\u001b[0m\n",
      "\u001b[38;5;19mLassoLarsCV                         3.19%\u001b[0m\n",
      "\u001b[38;5;19mLassoLarsIC                         3.17%\u001b[0m\n",
      "\u001b[38;5;19mLinearRegression                    3.20%\u001b[0m\n",
      "\u001b[38;5;19mLinearSVR                           -171.39%\u001b[0m\n",
      "\u001b[0mWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "\n",
      "\u001b[0mWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "\n",
      "\u001b[38;5;19mMLPRegressor                        2.85%\u001b[0m\n",
      "\u001b[0;31mMultiOutputRegressor                \u001b[1mFailed instantiating, model is likely a meta estimator:\u001b[0m\u001b[0;31m MultiOutputRegressor.__init__() missing 1 required positional argument: 'estimator'\u001b[0m\n",
      "\u001b[0;31mMultiTaskElasticNet                 \u001b[1mModel fit error:\u001b[0m\u001b[0;31m For mono-task outputs, use ElasticNet\u001b[0m\n",
      "\u001b[0;31mMultiTaskElasticNetCV               \u001b[1mModel fit error:\u001b[0m\u001b[0;31m For mono-task outputs, use ElasticNetCVCV\u001b[0m\n",
      "\u001b[0;31mMultiTaskLasso                      \u001b[1mModel fit error:\u001b[0m\u001b[0;31m For mono-task outputs, use ElasticNet\u001b[0m\n",
      "\u001b[0;31mMultiTaskLassoCV                    \u001b[1mModel fit error:\u001b[0m\u001b[0;31m For mono-task outputs, use LassoCVCV\u001b[0m\n",
      "\u001b[38;5;19mNuSVR                               2.17%\u001b[0m\n",
      "\u001b[38;5;19mOrthogonalMatchingPursuit           -0.01%\u001b[0m\n",
      "\u001b[38;5;19mOrthogonalMatchingPursuitCV         3.18%\u001b[0m\n",
      "\u001b[0mWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "\u001b[0;31mPLSCanonical                        \u001b[1mModel fit error:\u001b[0m\u001b[0;31m `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\u001b[0m\n",
      "\u001b[38;5;19mPLSRegression                       3.18%\u001b[0m\n",
      "\u001b[38;5;19mPassiveAggressiveRegressor          -103.41%\u001b[0m\n",
      "\u001b[38;5;19mPoissonRegressor                    0.13%\u001b[0m\n",
      "\u001b[38;5;19mRANSACRegressor                     -20.99%\u001b[0m\n",
      "\u001b[38;5;19mRadiusNeighborsRegressor            17.40%\u001b[0m\n",
      "\u001b[38;5;19mRandomForestRegressor               -21.01%\u001b[0m\n",
      "\u001b[0;31mRegressorChain                      \u001b[1mFailed instantiating, model is likely a meta estimator:\u001b[0m\u001b[0;31m _BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\u001b[0m\n",
      "\u001b[38;5;19mRidge                               2.79%\u001b[0m\n",
      "\u001b[38;5;19mRidgeCV                             3.20%\u001b[0m\n",
      "\u001b[38;5;19mSGDRegressor                        -34078022089602541459341312.00%\u001b[0m\n",
      "\u001b[38;5;19mSVR                                 -1.32%\u001b[0m\n",
      "\u001b[0;31mStackingRegressor                   \u001b[1mFailed instantiating, model is likely a meta estimator:\u001b[0m\u001b[0;31m StackingRegressor.__init__() missing 1 required positional argument: 'estimators'\u001b[0m\n",
      "\u001b[38;5;19mTheilSenRegressor                   2.37%\u001b[0m\n",
      "\u001b[38;5;19mTransformedTargetRegressor          3.20%\u001b[0m\n",
      "\u001b[38;5;19mTweedieRegressor                    0.14%\u001b[0m\n",
      "\u001b[0;31mVotingRegressor                     \u001b[1mFailed instantiating, model is likely a meta estimator:\u001b[0m\u001b[0;31m VotingRegressor.__init__() missing 1 required positional argument: 'estimators'\u001b[0m\n",
      "\u001b[0m-----------------------------------------------------\n",
      "RESULTS TABLE                       CV R^2\n",
      "\u001b[38;5;19mRadiusNeighborsRegressor            17.40%\n",
      "\u001b[38;5;19mHistGradientBoostingRegressor       11.00%\n",
      "\u001b[38;5;19mGradientBoostingRegressor           7.49%\n",
      "\u001b[38;5;19mBayesianRidge                       3.20%\n",
      "\u001b[38;5;19mLars                                3.20%\n",
      "\u001b[38;5;19mLinearRegression                    3.20%\n",
      "\u001b[38;5;19mTransformedTargetRegressor          3.20%\n",
      "\u001b[38;5;19mRidgeCV                             3.20%\n",
      "\u001b[38;5;19mLarsCV                              3.19%\n",
      "\u001b[38;5;19mLassoLarsCV                         3.19%\n",
      "\u001b[38;5;19mPLSRegression                       3.18%\n",
      "\u001b[38;5;19mOrthogonalMatchingPursuitCV         3.18%\n",
      "\u001b[38;5;19mLassoLarsIC                         3.17%\n",
      "\u001b[38;5;19mARDRegression                       3.16%\n",
      "\u001b[38;5;19mMLPRegressor                        2.85%\n",
      "\u001b[38;5;19mRidge                               2.79%\n",
      "\u001b[38;5;19mTheilSenRegressor                   2.37%\n",
      "\u001b[38;5;19mNuSVR                               2.17%\n",
      "\u001b[38;5;19mLassoCV                             1.34%\n",
      "\u001b[38;5;19mKernelRidge                         0.72%\n",
      "\u001b[38;5;19mAdaBoostRegressor                   0.56%\n",
      "\u001b[38;5;19mTweedieRegressor                    0.14%\n",
      "\u001b[38;5;19mElasticNet                          0.14%\n",
      "\u001b[38;5;19mPoissonRegressor                    0.13%\n",
      "\u001b[38;5;19mLasso                               0.13%\n",
      "\u001b[38;5;19mLassoLars                           0.13%\n",
      "\u001b[38;5;19mGammaRegressor                      0.13%\n",
      "\u001b[38;5;19mDummyRegressor                      -0.00%\n",
      "\u001b[38;5;19mElasticNetCV                        -0.00%\n",
      "\u001b[38;5;19mOrthogonalMatchingPursuit           -0.01%\n",
      "\u001b[38;5;19mSVR                                 -1.32%\n",
      "\u001b[38;5;19mHuberRegressor                      -1.81%\n",
      "\u001b[38;5;19mGaussianProcessRegressor            -3.91%\n",
      "\u001b[38;5;19mKNeighborsRegressor                 -6.87%\n",
      "\u001b[38;5;19mRANSACRegressor                     -20.99%\n",
      "\u001b[38;5;19mRandomForestRegressor               -21.01%\n",
      "\u001b[38;5;19mBaggingRegressor                    -23.05%\n",
      "\u001b[38;5;19mDecisionTreeRegressor               -25.19%\n",
      "\u001b[38;5;19mExtraTreesRegressor                 -25.20%\n",
      "\u001b[38;5;19mExtraTreeRegressor                  -25.28%\n",
      "\u001b[38;5;19mPassiveAggressiveRegressor          -103.41%\n",
      "\u001b[38;5;19mLinearSVR                           -171.39%\n",
      "\u001b[38;5;19mSGDRegressor                        -34078022089602541459341312.00%\n",
      "\u001b[0;31mMultiOutputRegressor                FAIL - instantiating\n",
      "\u001b[0;31mRegressorChain                      FAIL - instantiating\n",
      "\u001b[0;31mStackingRegressor                   FAIL - instantiating\n",
      "\u001b[0;31mVotingRegressor                     FAIL - instantiating\n",
      "\u001b[0;31mCCA                                 FAIL - Fitting\n",
      "\u001b[0;31mIsotonicRegression                  FAIL - Fitting\n",
      "\u001b[0;31mMultiTaskElasticNet                 FAIL - Fitting\n",
      "\u001b[0;31mMultiTaskElasticNetCV               FAIL - Fitting\n",
      "\u001b[0;31mMultiTaskLasso                      FAIL - Fitting\n",
      "\u001b[0;31mMultiTaskLassoCV                    FAIL - Fitting\n",
      "\u001b[0;31mPLSCanonical                        FAIL - Fitting\n",
      "\u001b[0m-----------------------------------------------------\n",
      "BEST MODEL:                         \u001b[0;32m\u001b[1mRadiusNeighborsRegressor\u001b[0m\n",
      "CV R^2:                             \u001b[0;32m17.4030%\u001b[0m\n",
      "R^2:                                \u001b[0;32m21.0676%\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "best_model_name_OVL, best_model_OVL, y_pred_OVL, residuals_OVL, results_table_OVL = get_residuals(asml_geo_data, asml['OVL'], models = estimators, random_seed = 123, timeout= 120, display_warnings = True, print_results_table = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2702c79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL ----------------------------- CV R^2\n",
      "\u001b[38;5;19mARDRegression                       44.21%\u001b[0m\n",
      "\u001b[38;5;19mAdaBoostRegressor                   50.14%\u001b[0m\n",
      "\u001b[38;5;19mBaggingRegressor                    40.83%\u001b[0m\n",
      "\u001b[38;5;19mBayesianRidge                       44.24%\u001b[0m\n",
      "\u001b[0;31mCCA                                 \u001b[1mModel fit error:\u001b[0m\u001b[0;31m `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\u001b[0m\n",
      "\u001b[38;5;19mDecisionTreeRegressor               39.82%\u001b[0m\n",
      "\u001b[38;5;19mDummyRegressor                      -0.04%\u001b[0m\n",
      "\u001b[38;5;19mElasticNet                          -0.04%\u001b[0m\n",
      "\u001b[38;5;19mElasticNetCV                        0.58%\u001b[0m\n",
      "\u001b[38;5;19mExtraTreeRegressor                  39.75%\u001b[0m\n",
      "\u001b[38;5;19mExtraTreesRegressor                 39.82%\u001b[0m\n",
      "\u001b[0;31mGammaRegressor                      \u001b[1mModel fit error:\u001b[0m\u001b[0;31m Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\u001b[0m\n",
      "\u001b[38;5;19mGaussianProcessRegressor            50.01%\u001b[0m\n",
      "\u001b[38;5;19mGradientBoostingRegressor           55.49%\u001b[0m\n",
      "\u001b[38;5;19mHistGradientBoostingRegressor       54.90%\u001b[0m\n",
      "\u001b[38;5;19mHuberRegressor                      -12.14%\u001b[0m\n",
      "\u001b[0;31mIsotonicRegression                  \u001b[1mModel fit error:\u001b[0m\u001b[0;31m Isotonic regression input X should be a 1d array or 2d array with 1 feature\u001b[0m\n",
      "\u001b[38;5;19mKNeighborsRegressor                 43.58%\u001b[0m\n",
      "\u001b[38;5;19mKernelRidge                         5.86%\u001b[0m\n",
      "\u001b[38;5;19mLars                                44.24%\u001b[0m\n",
      "\u001b[38;5;19mLarsCV                              44.24%\u001b[0m\n",
      "\u001b[0mWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=4.467e-05, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "\u001b[0mWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.658e-05, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "\u001b[0mWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=7.448e-07, with an active set of 5 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "\u001b[0mWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=9.007e-05, with an active set of 4 regressors, and the smallest cholesky pivot element being 8.429e-08. Reduce max_iter or increase eps parameters.\n",
      "\n",
      "\u001b[38;5;19mLasso                               -0.04%\u001b[0m\n",
      "\u001b[38;5;19mLassoCV                             42.43%\u001b[0m\n",
      "\u001b[38;5;19mLassoLars                           -0.04%\u001b[0m\n",
      "\u001b[38;5;19mLassoLarsCV                         44.24%\u001b[0m\n",
      "\u001b[38;5;19mLassoLarsIC                         44.24%\u001b[0m\n",
      "\u001b[38;5;19mLinearRegression                    44.24%\u001b[0m\n",
      "\u001b[38;5;19mLinearSVR                           -20.28%\u001b[0m\n",
      "\u001b[0mWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "\n",
      "\u001b[0mWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "\n",
      "\u001b[38;5;19mMLPRegressor                        1.21%\u001b[0m\n",
      "\u001b[0;31mMultiOutputRegressor                \u001b[1mFailed instantiating, model is likely a meta estimator:\u001b[0m\u001b[0;31m MultiOutputRegressor.__init__() missing 1 required positional argument: 'estimator'\u001b[0m\n",
      "\u001b[0;31mMultiTaskElasticNet                 \u001b[1mModel fit error:\u001b[0m\u001b[0;31m For mono-task outputs, use ElasticNet\u001b[0m\n",
      "\u001b[0;31mMultiTaskElasticNetCV               \u001b[1mModel fit error:\u001b[0m\u001b[0;31m For mono-task outputs, use ElasticNetCVCV\u001b[0m\n",
      "\u001b[0;31mMultiTaskLasso                      \u001b[1mModel fit error:\u001b[0m\u001b[0;31m For mono-task outputs, use ElasticNet\u001b[0m\n",
      "\u001b[0;31mMultiTaskLassoCV                    \u001b[1mModel fit error:\u001b[0m\u001b[0;31m For mono-task outputs, use LassoCVCV\u001b[0m\n",
      "\u001b[38;5;19mNuSVR                               -10.08%\u001b[0m\n",
      "\u001b[38;5;19mOrthogonalMatchingPursuit           -0.09%\u001b[0m\n",
      "\u001b[38;5;19mOrthogonalMatchingPursuitCV         44.24%\u001b[0m\n",
      "\u001b[0mWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.\n",
      "\n",
      "\u001b[0;31mPLSCanonical                        \u001b[1mModel fit error:\u001b[0m\u001b[0;31m `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.\u001b[0m\n",
      "\u001b[38;5;19mPLSRegression                       44.22%\u001b[0m\n",
      "\u001b[38;5;19mPassiveAggressiveRegressor          -117.04%\u001b[0m\n",
      "\u001b[38;5;19mPoissonRegressor                    2.04%\u001b[0m\n",
      "\u001b[38;5;19mRANSACRegressor                     -23.72%\u001b[0m\n",
      "\u001b[38;5;19mRadiusNeighborsRegressor            -0.07%\u001b[0m\n",
      "\u001b[38;5;19mRandomForestRegressor               42.14%\u001b[0m\n",
      "\u001b[0;31mRegressorChain                      \u001b[1mFailed instantiating, model is likely a meta estimator:\u001b[0m\u001b[0;31m _BaseChain.__init__() missing 1 required positional argument: 'base_estimator'\u001b[0m\n",
      "\u001b[38;5;19mRidge                               38.00%\u001b[0m\n",
      "\u001b[38;5;19mRidgeCV                             44.08%\u001b[0m\n",
      "\u001b[38;5;19mSGDRegressor                        -120753290183224613404672.00%\u001b[0m\n",
      "\u001b[38;5;19mSVR                                 -23.14%\u001b[0m\n",
      "\u001b[0;31mStackingRegressor                   \u001b[1mFailed instantiating, model is likely a meta estimator:\u001b[0m\u001b[0;31m StackingRegressor.__init__() missing 1 required positional argument: 'estimators'\u001b[0m\n",
      "\u001b[38;5;19mTheilSenRegressor                   41.88%\u001b[0m\n",
      "\u001b[38;5;19mTransformedTargetRegressor          44.24%\u001b[0m\n",
      "\u001b[38;5;19mTweedieRegressor                    -0.02%\u001b[0m\n",
      "\u001b[0;31mVotingRegressor                     \u001b[1mFailed instantiating, model is likely a meta estimator:\u001b[0m\u001b[0;31m VotingRegressor.__init__() missing 1 required positional argument: 'estimators'\u001b[0m\n",
      "\u001b[0m-----------------------------------------------------\n",
      "RESULTS TABLE                       CV R^2\n",
      "\u001b[38;5;19mGradientBoostingRegressor           55.49%\n",
      "\u001b[38;5;19mHistGradientBoostingRegressor       54.90%\n",
      "\u001b[38;5;19mAdaBoostRegressor                   50.14%\n",
      "\u001b[38;5;19mGaussianProcessRegressor            50.01%\n",
      "\u001b[38;5;19mLarsCV                              44.24%\n",
      "\u001b[38;5;19mLinearRegression                    44.24%\n",
      "\u001b[38;5;19mTransformedTargetRegressor          44.24%\n",
      "\u001b[38;5;19mOrthogonalMatchingPursuitCV         44.24%\n",
      "\u001b[38;5;19mLars                                44.24%\n",
      "\u001b[38;5;19mLassoLarsCV                         44.24%\n",
      "\u001b[38;5;19mLassoLarsIC                         44.24%\n",
      "\u001b[38;5;19mBayesianRidge                       44.24%\n",
      "\u001b[38;5;19mPLSRegression                       44.22%\n",
      "\u001b[38;5;19mARDRegression                       44.21%\n",
      "\u001b[38;5;19mRidgeCV                             44.08%\n",
      "\u001b[38;5;19mKNeighborsRegressor                 43.58%\n",
      "\u001b[38;5;19mLassoCV                             42.43%\n",
      "\u001b[38;5;19mRandomForestRegressor               42.14%\n",
      "\u001b[38;5;19mTheilSenRegressor                   41.88%\n",
      "\u001b[38;5;19mBaggingRegressor                    40.83%\n",
      "\u001b[38;5;19mDecisionTreeRegressor               39.82%\n",
      "\u001b[38;5;19mExtraTreesRegressor                 39.82%\n",
      "\u001b[38;5;19mExtraTreeRegressor                  39.75%\n",
      "\u001b[38;5;19mRidge                               38.00%\n",
      "\u001b[38;5;19mKernelRidge                         5.86%\n",
      "\u001b[38;5;19mPoissonRegressor                    2.04%\n",
      "\u001b[38;5;19mMLPRegressor                        1.21%\n",
      "\u001b[38;5;19mElasticNetCV                        0.58%\n",
      "\u001b[38;5;19mTweedieRegressor                    -0.02%\n",
      "\u001b[38;5;19mDummyRegressor                      -0.04%\n",
      "\u001b[38;5;19mElasticNet                          -0.04%\n",
      "\u001b[38;5;19mLassoLars                           -0.04%\n",
      "\u001b[38;5;19mLasso                               -0.04%\n",
      "\u001b[38;5;19mRadiusNeighborsRegressor            -0.07%\n",
      "\u001b[38;5;19mOrthogonalMatchingPursuit           -0.09%\n",
      "\u001b[38;5;19mNuSVR                               -10.08%\n",
      "\u001b[38;5;19mHuberRegressor                      -12.14%\n",
      "\u001b[38;5;19mLinearSVR                           -20.28%\n",
      "\u001b[38;5;19mSVR                                 -23.14%\n",
      "\u001b[38;5;19mRANSACRegressor                     -23.72%\n",
      "\u001b[38;5;19mPassiveAggressiveRegressor          -117.04%\n",
      "\u001b[38;5;19mSGDRegressor                        -120753290183224613404672.00%\n",
      "\u001b[0;31mMultiOutputRegressor                FAIL - instantiating\n",
      "\u001b[0;31mRegressorChain                      FAIL - instantiating\n",
      "\u001b[0;31mStackingRegressor                   FAIL - instantiating\n",
      "\u001b[0;31mVotingRegressor                     FAIL - instantiating\n",
      "\u001b[0;31mCCA                                 FAIL - Fitting\n",
      "\u001b[0;31mGammaRegressor                      FAIL - Fitting\n",
      "\u001b[0;31mIsotonicRegression                  FAIL - Fitting\n",
      "\u001b[0;31mMultiTaskElasticNet                 FAIL - Fitting\n",
      "\u001b[0;31mMultiTaskElasticNetCV               FAIL - Fitting\n",
      "\u001b[0;31mMultiTaskLasso                      FAIL - Fitting\n",
      "\u001b[0;31mMultiTaskLassoCV                    FAIL - Fitting\n",
      "\u001b[0;31mPLSCanonical                        FAIL - Fitting\n",
      "\u001b[0m-----------------------------------------------------\n",
      "BEST MODEL:                         \u001b[0;32m\u001b[1mGradientBoostingRegressor\u001b[0m\n",
      "CV R^2:                             \u001b[0;32m55.4870%\u001b[0m\n",
      "R^2:                                \u001b[0;32m57.4199%\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_model_name_Yield, best_model_Yield, y_pred_Yield, residuals_Yield, results_table_Yield = get_residuals(asml_geo_data, asml['Yield'], models = estimators, random_seed = 123, timeout= 120, display_warnings = True, print_results_table = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a58be3f",
   "metadata": {},
   "source": [
    "### Residual Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11958078",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wafer_id</th>\n",
       "      <th>res_Yield</th>\n",
       "      <th>res_OVL</th>\n",
       "      <th>res_L1_CD</th>\n",
       "      <th>res_L2_CD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.338796</td>\n",
       "      <td>-0.660477</td>\n",
       "      <td>1.313265</td>\n",
       "      <td>0.337432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-2.073921</td>\n",
       "      <td>-0.187518</td>\n",
       "      <td>1.626656</td>\n",
       "      <td>-0.385745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.062992</td>\n",
       "      <td>-0.143817</td>\n",
       "      <td>1.240921</td>\n",
       "      <td>-0.535638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.608892</td>\n",
       "      <td>0.155504</td>\n",
       "      <td>1.385403</td>\n",
       "      <td>0.074616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.177048</td>\n",
       "      <td>0.280366</td>\n",
       "      <td>0.956613</td>\n",
       "      <td>-0.617753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7345</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.356056</td>\n",
       "      <td>1.101372</td>\n",
       "      <td>0.456907</td>\n",
       "      <td>-0.671538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7346</th>\n",
       "      <td>5</td>\n",
       "      <td>-3.060945</td>\n",
       "      <td>1.213893</td>\n",
       "      <td>0.247188</td>\n",
       "      <td>-0.338752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7347</th>\n",
       "      <td>5</td>\n",
       "      <td>-8.416580</td>\n",
       "      <td>1.297321</td>\n",
       "      <td>0.552276</td>\n",
       "      <td>-0.722560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7348</th>\n",
       "      <td>5</td>\n",
       "      <td>-12.667498</td>\n",
       "      <td>1.740963</td>\n",
       "      <td>0.097877</td>\n",
       "      <td>-0.458051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7349</th>\n",
       "      <td>5</td>\n",
       "      <td>-14.670006</td>\n",
       "      <td>2.112341</td>\n",
       "      <td>0.166561</td>\n",
       "      <td>-0.387118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7350 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      wafer_id  res_Yield   res_OVL  res_L1_CD  res_L2_CD\n",
       "0            1   0.338796 -0.660477   1.313265   0.337432\n",
       "1            1  -2.073921 -0.187518   1.626656  -0.385745\n",
       "2            1  -0.062992 -0.143817   1.240921  -0.535638\n",
       "3            1   1.608892  0.155504   1.385403   0.074616\n",
       "4            1   0.177048  0.280366   0.956613  -0.617753\n",
       "...        ...        ...       ...        ...        ...\n",
       "7345         5  -0.356056  1.101372   0.456907  -0.671538\n",
       "7346         5  -3.060945  1.213893   0.247188  -0.338752\n",
       "7347         5  -8.416580  1.297321   0.552276  -0.722560\n",
       "7348         5 -12.667498  1.740963   0.097877  -0.458051\n",
       "7349         5 -14.670006  2.112341   0.166561  -0.387118\n",
       "\n",
       "[7350 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asml_res = asml[['wafer_id']].copy()\n",
    "asml_res = asml_res.assign(\n",
    "    res_Yield = residuals_Yield,\n",
    "    res_OVL=residuals_OVL,\n",
    "    res_L1_CD=residuals_L1_CD,\n",
    "    res_L2_CD=residuals_L2_CD)\n",
    "asml_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4837de1-c23e-401e-afaf-b9998cd7d21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging my code with the code from Phil\n",
    "\n",
    "# transforming my df into an excel file\n",
    "\n",
    "asml_res.to_excel('ASML case data 2024 bias removed.xlsx', index=False)  # `index=False` means do not write row indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c19d808-7eae-424c-a92c-ffde0de8d79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_excel_to_arrays(file_path):\n",
    "    # Load the Excel file\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "    \n",
    "    # Create an empty dictionary to hold sheet names and arrays\n",
    "    arrays_dict = {}\n",
    "    \n",
    "    # Iterate through each sheet in the Excel file\n",
    "    for sheet_name in xls.sheet_names:\n",
    "        # Read the sheet into a DataFrame\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "        \n",
    "        # Get the headers from the first row\n",
    "        headers = df.columns.tolist()\n",
    "\n",
    "        # Convert the DataFrame to a NumPy array\n",
    "        array = df.to_numpy()\n",
    "        \n",
    "        # Add the array to the dictionary with sheet name as key\n",
    "        arrays_dict[sheet_name] = array\n",
    "    \n",
    "    return arrays_dict, headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39e27cf5-99d2-4b09-b46c-c6b7aa9399bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Sheet1'])\n"
     ]
    }
   ],
   "source": [
    "print(arrays_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fba1d44f-146a-4a1b-9fe4-41fb551f1f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \u001b[38;5;19mOLS completed\u001b[0m\n",
      "\u001b[0;32mCV score: -240.48\n",
      "\n",
      " \u001b[38;5;19mOLS with Ridge completed\u001b[0m\n",
      "best model parameters: {'alpha': 0.0, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': None, 'solver': 'auto', 'tol': 0.0001}\n",
      "\u001b[0;32mbest CV score: -240.48\u001b[0m\n",
      "\n",
      " \u001b[38;5;19mOLS with Adaptive Lasso\u001b[0m\n",
      "\u001b[0;32mCV score: -240.12\n",
      "\n",
      " \u001b[38;5;19mKNN completed\u001b[0m\n",
      "best model parameters: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}\n",
      "\u001b[0;32mbest CV score: -247.23\u001b[0m\n",
      "\n",
      " \u001b[38;5;19mDecision Tree completed\u001b[0m\n",
      "best max depth: 40\n",
      "best model parameters: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 40, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': None, 'splitter': 'best'}\n",
      "\u001b[0;32mbest CV score: -309.24\u001b[0m\n",
      "\n",
      " Fitting SVR\n",
      "fitting model in cross validation with:\n",
      " C = 0.1\n",
      " kernel = linear\n",
      " kernel = rbf\n",
      "fitting model in cross validation with:\n",
      " C = 1\n",
      " kernel = linear\n",
      " kernel = rbf\n",
      "fitting model in cross validation with:\n",
      " C = 10\n",
      " kernel = linear\n",
      " kernel = rbf\n",
      "\n",
      " \u001b[38;5;19mSVR completed\u001b[0m\n",
      "best C: 0.1\n",
      "best kernel: linear\n",
      "best model parameters: {'C': 0.1, 'cache_size': 200, 'coef0': 0.0, 'degree': 3, 'epsilon': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\u001b[0;32mbest CV score: -239.31\u001b[0m\n",
      "\n",
      " Fitting Random Forest\n",
      "fitting model in cross validation with n_estimators = 1\n",
      "fitting model in cross validation with n_estimators = 5\n",
      "fitting model in cross validation with n_estimators = 10\n",
      "fitting model in cross validation with n_estimators = 50\n",
      "fitting model in cross validation with n_estimators = 100\n",
      "\n",
      " \u001b[38;5;19mRandom Forest completed\u001b[0m\n",
      "best number of estimators: 1\n",
      "best model parameters: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 40, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': None, 'splitter': 'best'}\n",
      "\u001b[0;32mbest CV score: -316.17\u001b[0m\n",
      "\n",
      " Fitting Gradient Boosting\n",
      "fitting model in cross validation with n_estimators = 100\n",
      "fitting model in cross validation with n_estimators = 150\n",
      "fitting model in cross validation with n_estimators = 200\n",
      "\n",
      " \u001b[38;5;19mGradient Boosting completed\u001b[0m\n",
      "best number of estimators: 200\n",
      "best model parameters: {'alpha': 0.9, 'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 200, 'n_iter_no_change': None, 'random_state': None, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}\n",
      "\u001b[0;32mbest CV score: -219.69\u001b[0m\n",
      "\n",
      " Fitting XGBoost\n",
      "fitting model in cross validation with n_estimators = 1\n",
      "fitting model in cross validation with n_estimators = 5\n",
      "fitting model in cross validation with n_estimators = 10\n",
      "fitting model in cross validation with n_estimators = 50\n",
      "fitting model in cross validation with n_estimators = 100\n",
      "\n",
      " \u001b[38;5;19mGradient Boosting completed\u001b[0m\n",
      "best number of estimators: 1\n",
      "best model parameters: {'objective': 'reg:squarederror', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': 1, 'n_jobs': -1, 'num_parallel_tree': None, 'random_state': None, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None}\n",
      "\u001b[0;32mbest CV score: -258.12\u001b[0m\n",
      "\n",
      " Fitting Elastic Net\n",
      "fitting model in cross validation with:\n",
      " alpha = 0.01\n",
      " l1_ratio = 0.2\n",
      " l1_ratio = 0.5\n",
      " l1_ratio = 0.8\n",
      "fitting model in cross validation with:\n",
      " alpha = 0.1\n",
      " l1_ratio = 0.2\n",
      " l1_ratio = 0.5\n",
      " l1_ratio = 0.8\n",
      "fitting model in cross validation with:\n",
      " alpha = 1\n",
      " l1_ratio = 0.2\n",
      " l1_ratio = 0.5\n",
      " l1_ratio = 0.8\n",
      "\n",
      " \u001b[38;5;19mElastic Net completed\u001b[0m\n",
      "best alpha: 0.01\n",
      "best l1_ratio: 0.5\n",
      "best model parameters: {'alpha': 0.01, 'copy_X': True, 'fit_intercept': True, 'l1_ratio': 0.5, 'max_iter': 1000, 'positive': False, 'precompute': False, 'random_state': None, 'selection': 'cyclic', 'tol': 0.0001, 'warm_start': False}\n",
      "\u001b[0;32mbest CV score: -240.39\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# CODE FROM PHIL\n",
    "\n",
    "# I commented out the load_excel_to_arrays, I was not able to import if for some reason. I pasted it above for this reason.\n",
    "\n",
    "\n",
    "#import ASML_functions as fn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import Lasso, Ridge, LassoLarsCV, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Load the data\n",
    "file_path = 'ASML case data 2024 bias removed.xlsx'\n",
    "\n",
    "#arrays_dict, headers = fn.load_excel_to_arrays(file_path)\n",
    "arrays_dict, headers = load_excel_to_arrays(file_path)\n",
    "\n",
    "# Sample the first wafer\n",
    "\n",
    "# with the data I have, the array was just 'Sheet1'\n",
    "df_reg = arrays_dict['Sheet1'][:, -4:]\n",
    "#df_reg = arrays_dict['Wafer 1'][:, -4:]\n",
    "# (OVL, L1_CD, L2_CD, OVL_L2_CD, OVL_2, L2CD_2_L1CD)\n",
    "\n",
    "OVL_L2CD  = df_reg[:, 1] * df_reg[:, 3]\n",
    "OVL_2  = df_reg[:, 1] * df_reg[:, 1]\n",
    "L2CD_2_L1CD = df_reg[:, 3] * df_reg[:, 3] * df_reg[:, 2]\n",
    "\n",
    "df_reg = np.hstack((df_reg, np.array([OVL_L2CD, OVL_2, L2CD_2_L1CD]).T))\n",
    "\n",
    "# Load the data\n",
    "file_path = 'ASML case data 2024.xlsx'\n",
    "#arrays_dict, headers = fn.load_excel_to_arrays(file_path)\n",
    "arrays_dict, headers = load_excel_to_arrays(file_path)\n",
    "# y = df[:, -4]\n",
    "\n",
    "# Split data into features and target\n",
    "X = df_reg[:, 1:]\n",
    "y = df_reg[:, 0]\n",
    "\n",
    "# function for testing:\n",
    "# OLS, Ridge/Lasso, Adaptive Lasso, kNN, Decision Tree\n",
    "def function_tester(cv_size:int = 10, loss_function:str = 'neg_mean_squared_error'):\n",
    "\n",
    "    BLUE = '\\033[38;5;19m'\n",
    "    GREEN = '\\033[0;32m'\n",
    "    BOLD = '\\033[1m'\n",
    "    RESET = '\\033[0m'\n",
    "\n",
    "    # Ordinary Least Squares (OLS) regression\n",
    "    ols_model = LinearRegression()\n",
    "    ols_scores = cross_val_score(ols_model, X, y, cv=cv_size, scoring=loss_function)\n",
    "    ols_scores_mean = np.mean(ols_scores)\n",
    "    print(f'\\n {BLUE}OLS completed{RESET}')\n",
    "    print(f'{GREEN}average CV score: {ols_scores_mean:.2f}')\n",
    "\n",
    "    # OLS with Ridge regression\n",
    "    alpha_best = 0\n",
    "    ridge_model_best = None\n",
    "    ridge_scores_mean_best = 1e99\n",
    "    ridge_scores_best = None\n",
    "    for alpha in range(11):\n",
    "        alpha_1 = alpha * 0.1\n",
    "        ridge_model = Ridge(alpha=alpha_1)\n",
    "        ridge_scores = cross_val_score(ridge_model, X, y, cv=cv_size, scoring=loss_function)\n",
    "        if np.mean(ridge_scores) < ridge_scores_mean_best:\n",
    "            alpha_best = alpha_1\n",
    "            ridge_model_best = ridge_model\n",
    "            ridge_scores_mean_best = np.mean(ridge_scores)\n",
    "            ridge_scores_best = ridge_scores\n",
    "    print(f'\\n {BLUE}OLS with Ridge completed{RESET}')\n",
    "    print(f'best model parameters: {ridge_model_best.get_params()}')\n",
    "    print(f'{GREEN}average CV score using best parameters: {ridge_scores_mean_best:.2f}{RESET}')\n",
    "\n",
    "    # OLS with Adaptive Lasso\n",
    "    lasso_adaptive_model = LassoLarsCV(cv=10)\n",
    "    lasso_adaptive_scores = cross_val_score(lasso_adaptive_model, X, y, cv=cv_size, scoring=loss_function)\n",
    "    lasso_adaptive_mean_scores = np.mean(lasso_adaptive_scores)\n",
    "    print(f'\\n {BLUE}OLS with Adaptive Lasso{RESET}')\n",
    "    print(f'{GREEN}average CV score: {lasso_adaptive_mean_scores:.2f}')\n",
    "\n",
    "    # k-Nearest Neighbors (KNN)\n",
    "    n_neighbors_best = 1\n",
    "    knn_model_best = None\n",
    "    knn_scores_mean_best = 1e99\n",
    "    knn_scores_best = None\n",
    "    for n_neighbors_1 in range(5, 51, 5):\n",
    "        knn_model = KNeighborsRegressor(n_neighbors=5)  # You can adjust the number of neighbors\n",
    "        knn_scores = cross_val_score(knn_model, X, y, cv=cv_size, scoring=loss_function)\n",
    "        if np.mean(knn_scores) < knn_scores_mean_best:\n",
    "            n_neighbors_best = n_neighbors_1\n",
    "            knn_model_best = knn_model\n",
    "            knn_scores_mean_best = np.mean(knn_scores)\n",
    "            knn_scores_best = knn_scores\n",
    "    print(f'\\n {BLUE}KNN completed{RESET}')\n",
    "    print(f'best model parameters: {knn_model_best.get_params()}')\n",
    "    print(f'{GREEN}average CV score using best parameters: {knn_scores_mean_best:.2f}{RESET}')\n",
    "    \n",
    "    # Decision Tree with pruning\n",
    "    max_depth_best = 0\n",
    "    tree_model_best = None\n",
    "    tree_scores_mean_best = 1e99\n",
    "    tree_scores_best = None\n",
    "    for max_depth_1 in range(5, 51, 5):\n",
    "        tree_model = DecisionTreeRegressor(max_depth=max_depth_1)  # You can adjust the maximum depth\n",
    "        tree_scores = cross_val_score(tree_model, X, y, cv=cv_size, scoring=loss_function)\n",
    "        if np.mean(tree_scores) < tree_scores_mean_best:\n",
    "            max_depth_best = max_depth_1\n",
    "            tree_model_best = tree_model\n",
    "            tree_scores_mean_best = np.mean(tree_scores)\n",
    "            tree_scores_best = tree_scores\n",
    "    print(f'\\n {BLUE}Decision Tree completed{RESET}')\n",
    "    print(f'best max depth: {max_depth_best}')\n",
    "    print(f'best model parameters: {tree_model_best.get_params()}')\n",
    "    print(f'{GREEN}average CV score using best parameters: {tree_scores_mean_best:.2f}{RESET}')\n",
    "    \n",
    "    # SVR\n",
    "    print(f'\\n {BOLD}Fitting SVR{RESET}')\n",
    "    C_best = 1\n",
    "    kernel_best = 'rbf'\n",
    "    svr_scores_best = None\n",
    "    svr_scores_mean_best = 1e99\n",
    "    for C in [0.1, 1, 10]:\n",
    "        print('fitting model in cross validation with:')\n",
    "        print(f' C = {C}')\n",
    "        for kernel in ['linear', 'rbf']:\n",
    "            print(f' kernel = {kernel}')\n",
    "            svr_model = SVR(C=C, kernel=kernel)\n",
    "            svr_scores = cross_val_score(svr_model, X, y, cv=cv_size, scoring=loss_function)\n",
    "            if np.mean(svr_scores) < svr_scores_mean_best:\n",
    "                C_best = C\n",
    "                kernel_model_best = kernel\n",
    "                svr_model_best = svr_model\n",
    "                svr_scores_best = svr_scores\n",
    "                svr_scores_mean_best = np.mean(svr_scores)\n",
    "    print(f'\\n {BLUE}SVR completed{RESET}')\n",
    "    print(f'best C: {C_best}')\n",
    "    print(f'best kernel: {kernel_model_best}')\n",
    "    print(f'best model parameters: {svr_model_best.get_params()}')\n",
    "    print(f'{GREEN}average CV score using best parameters: {svr_scores_mean_best:.2f}{RESET}')\n",
    "    \n",
    "    # Random Forest with tuning for number of trees\n",
    "    print(f'\\n {BOLD}Fitting Random Forest{RESET}')\n",
    "    n_estimators_rf_best = 0\n",
    "    rf_scores_best = None\n",
    "    rf_scores_mean_best = 1e99\n",
    "    for n_estimators in [1, 5, 10, 50, 100]:\n",
    "        print(f'fitting model in cross validation with n_estimators = {n_estimators}')\n",
    "        rf_model = RandomForestRegressor(n_estimators=n_estimators, n_jobs = -1)\n",
    "        rf_scores = cross_val_score(rf_model, X, y, cv=cv_size, scoring=loss_function)\n",
    "        if np.mean(rf_scores) < rf_scores_mean_best:\n",
    "            n_estimators_rf_best = n_estimators\n",
    "            rf_model_best = rf_model\n",
    "            rf_scores_best = rf_scores\n",
    "            rf_scores_mean_best = np.mean(rf_scores)\n",
    "    print(f'\\n {BLUE}Random Forest completed{RESET}')\n",
    "    print(f'best number of estimators: {n_estimators_rf_best}')\n",
    "    print(f'best model parameters: {tree_model_best.get_params()}')\n",
    "    print(f'{GREEN}average CV score using best parameters: {rf_scores_mean_best:.2f}{RESET}')\n",
    "    \n",
    "    # Gradient Boosting with tuning for number of trees\n",
    "    print(f'\\n {BOLD}Fitting Gradient Boosting{RESET}')\n",
    "    gb_scores_best = None\n",
    "    gb_scores_mean_best = 1e99\n",
    "    n_estimators_gb_best = 0\n",
    "    for n_estimators in [100, 250, 400, 600]:\n",
    "        print(f'fitting model in cross validation with n_estimators = {n_estimators}')\n",
    "        gb_model = GradientBoostingRegressor(n_estimators=n_estimators)\n",
    "        gb_scores = cross_val_score(gb_model, X, y, cv=cv_size, scoring=loss_function)\n",
    "        if np.mean(gb_scores) < gb_scores_mean_best:\n",
    "            n_estimators_gb_best = n_estimators\n",
    "            gb_scores_best = gb_scores\n",
    "            gb_model_best = gb_model\n",
    "            gb_scores_mean_best = np.mean(gb_scores)\n",
    "    print(f'\\n {BLUE}Gradient Boosting completed{RESET}')\n",
    "    print(f'best number of estimators: {n_estimators_gb_best}')\n",
    "    print(f'best model parameters: {gb_model_best.get_params()}')\n",
    "    print(f'{GREEN}average CV score using best parameters: {gb_scores_mean_best:.2f}{RESET}')\n",
    "    \n",
    "    # XGBoost with tuning for number of trees\n",
    "    print(f'\\n {BOLD}Fitting XGBoost{RESET}')\n",
    "    xgb_scores_best = None\n",
    "    xgb_scores_mean_best = 1e99\n",
    "    for n_estimators in [1, 5, 10, 50, 100]:\n",
    "        print(f'fitting model in cross validation with n_estimators = {n_estimators}')\n",
    "        xgb_model = XGBRegressor(n_estimators=n_estimators,n_jobs=-1)\n",
    "        xgb_scores = cross_val_score(xgb_model, X, y, cv=cv_size, scoring=loss_function)\n",
    "        if np.mean(xgb_scores) < xgb_scores_mean_best:\n",
    "            xgb_scores_best = xgb_scores\n",
    "            xgb_model_best = xgb_model\n",
    "            n_estimators_xgb_best = n_estimators\n",
    "            xgb_scores_mean_best = np.mean(xgb_scores)\n",
    "    print(f'\\n {BLUE}Gradient Boosting completed{RESET}')\n",
    "    print(f'best number of estimators: {n_estimators_xgb_best}')\n",
    "    print(f'best model parameters: {xgb_model_best.get_params()}')\n",
    "    print(f'{GREEN}average CV score using best parameters: {xgb_scores_mean_best:.2f}{RESET}')\n",
    "    \n",
    "    # Elastic Net with tuning for alpha and l1_ratio\n",
    "    print(f'\\n {BOLD}Fitting Elastic Net{RESET}')\n",
    "    elastic_net_scores_best = None\n",
    "    elastic_net_scores_mean_best = 1e99\n",
    "    best_alpha = 0\n",
    "    best_l1_ratio = 0\n",
    "    for alpha in [0.01, 0.1, 1]:\n",
    "        print('fitting model in cross validation with:')\n",
    "        print(f' alpha = {alpha}')\n",
    "        for l1_ratio in [0.2, 0.5, 0.8]:\n",
    "            print(f' l1_ratio = {l1_ratio}')\n",
    "            en_model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "            elastic_net_scores = cross_val_score(en_model, X, y, cv=cv_size, scoring=loss_function)\n",
    "            if np.mean(elastic_net_scores) < elastic_net_scores_mean_best:\n",
    "                elastic_net_scores_best = elastic_net_scores\n",
    "                best_alpha = alpha\n",
    "                best_l1_ratio = l1_ratio\n",
    "                elastic_net_model_best = en_model\n",
    "                elastic_net_scores_mean_best = np.mean(elastic_net_scores)\n",
    "    print(f'\\n {BLUE}Elastic Net completed{RESET}')\n",
    "    print(f'best alpha: {best_alpha}')\n",
    "    print(f'best l1_ratio: {best_l1_ratio}')\n",
    "    print(f'best model parameters: {elastic_net_model_best.get_params()}')\n",
    "    print(f'{GREEN}average CV score using best parameters: {elastic_net_scores_mean_best:.2f}{RESET}')\n",
    "    \n",
    "    return (ols_scores, ridge_scores_best, lasso_adaptive_scores, knn_scores_best, tree_scores_best,\n",
    "           svr_scores_best, rf_scores_best, gb_scores_best, xgb_scores_best, elastic_net_scores_best)\n",
    "\n",
    "\n",
    "## Custom loss function\n",
    "# custom scoring function\n",
    "def custom_scoring_function(y_true, y_pred, alpha):\n",
    "    # Penalize values below alpha and favor values above alpha\n",
    "    score = ((y_pred >= alpha) * y_true).sum()  # penalize values below alpha\n",
    "    score += ((y_pred < alpha) * (y_true - alpha)).sum()  # reward values above alpha\n",
    "    return score\n",
    "\n",
    "# Create the scorer\n",
    "custom_scorer = make_scorer(custom_scoring_function, alpha=0.9)\n",
    "\n",
    "\n",
    "## Setting up the parameters\n",
    "# Set the CV sizes and loss functions\n",
    "cv_sizes = (10, 20, 50, 100)\n",
    "loss_functions = ('neg_mean_squared_error', 'neg_mean_absolute_percentage_error')\n",
    "\n",
    "\n",
    "## Executing the tests\n",
    "# for cv_size in cv_sizes:\n",
    "#     for loss_function in loss_functions:\n",
    "# Obtain the methods' scores5\n",
    "(ols_scores, ridge_scores_best, lasso_adaptive_scores, knn_scores_best, tree_scores_best,\n",
    "svr_scores_best, rf_scores_best, gb_scores_best, xgb_scores_best, elastic_net_scores_best) = function_tester(10, custom_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "69b13660-f715-4db3-b566-e1999df3a70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the scores\n",
    "plt.boxplot([ols_scores, ridge_scores_best, lasso_adaptive_scores, knn_scores_best, tree_scores_best,\n",
    "            svr_scores_best, rf_scores_best, gb_scores_best, xgb_scores_best, elastic_net_scores_best],\n",
    "            labels=['OLS', 'Ridge', 'Adaptive Lasso', 'KNN', 'Decision Tree', \n",
    "                    'SVR','Random Forest', 'Gradient Boosting','XGBoost','Elastic Net'])\n",
    "plt.ylabel(\"loss_function\")\n",
    "plt.title('Comparison of Regression Methods for CV size = ' + str(10))\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig('plot_cv' + str(10) + '_loss_function_' + \"loss_function\" + '.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
